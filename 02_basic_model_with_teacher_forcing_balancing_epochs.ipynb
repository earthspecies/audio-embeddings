{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 3.38 s, total: 32.7 s\n",
      "Wall time: 34.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17937758, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv('data/examples.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While attempting to train the model, it turned out that the reading and unpickling operation done at this scale, with so many files, is very computationally expensive.\n",
    "\n",
    "But the examples in the mfcc represenatations are very small. Let's read them all into the memory before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniq_fns = np.unique(df.target_fn.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# fn2feature = {}\n",
    "# for fn in uniq_fns:\n",
    "#     ary = pd.read_pickle(f'data/examples/{fn}.pkl')\n",
    "#     fn2feature[fn] = ary\n",
    "\n",
    "# pd.to_pickle(fn2feature, 'data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 16.6 s, total: 36 s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn2features = pd.read_pickle('data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(df.source_word.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# counter = Counter(df.source_word)\n",
    "\n",
    "# most_common_words = set([t[0] for t in counter.most_common(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect that reading the data from a file saved within numpy (`numpy.save`) is much less computationally expensive than unpickling it, but I might be wrong. Either way, at ~4 million of unique utterances, the dataset is small enough to comfortably fit within memory of a GCP instance (at ~53GBs used RAM during training).\n",
    "\n",
    "This might not be ideal for experimentation on home rigs. Saving the data using `numpy.save` and evaluating performance would definitely be a very interesting and useful exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_fn</th>\n",
       "      <th>target_fn</th>\n",
       "      <th>set_name</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>distance_from_target</th>\n",
       "      <th>audio_fpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>FELT</td>\n",
       "      <td>8af4aebcf4a74004b02db9f88d99e89a</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>THAT</td>\n",
       "      <td>8af4aebcf4a74004b02db9f88d99e89a</td>\n",
       "      <td>2f60546c930c47068ee0a129e6d51c39</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>2</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FELT</td>\n",
       "      <td>I</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>8af4aebcf4a74004b02db9f88d99e89a</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FELT</td>\n",
       "      <td>THAT</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>2f60546c930c47068ee0a129e6d51c39</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FELT</td>\n",
       "      <td>IT</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>155ad336d88c4cbf814a1237983b5b18</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>2</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_word target_word                         source_fn  \\\n",
       "0           I        FELT  8af4aebcf4a74004b02db9f88d99e89a   \n",
       "1           I        THAT  8af4aebcf4a74004b02db9f88d99e89a   \n",
       "2        FELT           I  1cb9442ec1a6468282da309756e2ff57   \n",
       "3        FELT        THAT  1cb9442ec1a6468282da309756e2ff57   \n",
       "4        FELT          IT  1cb9442ec1a6468282da309756e2ff57   \n",
       "\n",
       "                          target_fn         set_name  speaker_id  book_id  \\\n",
       "0  1cb9442ec1a6468282da309756e2ff57  train-clean-360        7000    83696   \n",
       "1  2f60546c930c47068ee0a129e6d51c39  train-clean-360        7000    83696   \n",
       "2  8af4aebcf4a74004b02db9f88d99e89a  train-clean-360        7000    83696   \n",
       "3  2f60546c930c47068ee0a129e6d51c39  train-clean-360        7000    83696   \n",
       "4  155ad336d88c4cbf814a1237983b5b18  train-clean-360        7000    83696   \n",
       "\n",
       "   distance_from_target  \\\n",
       "0                     1   \n",
       "1                     2   \n",
       "2                     1   \n",
       "3                     1   \n",
       "4                     2   \n",
       "\n",
       "                                                        audio_fpath  \n",
       "0  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "1  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "2  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "3  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "4  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = df[df.set_name.isin(['train-clean-360', 'train-clean-100', 'dev-clean'])]\n",
    "valid_examples = df[df.set_name == 'test-clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159688530, 1751292)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples.size, valid_examples.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.59 s, sys: 208 ms, total: 5.8 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_fns = df.source_fn.unique()\n",
    "np.random.shuffle(unique_fns)\n",
    "lengths = []\n",
    "for i, features in enumerate(fn2features.values()):\n",
    "    lengths.append(features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.028019713968394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f00794f1390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean = -5\n",
    "dataset_std = 15\n",
    "\n",
    "def normalize_data(ary):\n",
    "    return (ary - dataset_mean) / dataset_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_list():\n",
    "    return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# word2row_idxs = defaultdict(empty_list)\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     word2row_idxs[row.source_word].append(idx)\n",
    "    \n",
    "# pd.to_pickle(word2row_idxs, 'data/word2row_idxs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2row_idxs = pd.read_pickle('data/word2row_idxs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(fn, pad_to=40, pad_left=False):\n",
    "    ary = fn2features[fn][:pad_to]\n",
    "    example = np.zeros((pad_to, 13))\n",
    "    if pad_left:\n",
    "        example[-ary.shape[0]:, :] = ary\n",
    "    else: example[:ary.shape[0], :] = ary\n",
    "    return example.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.nan in vocab: vocab.remove(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, n):\n",
    "        self.vocab = vocab * n\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "    def __getitem__(self, idx):\n",
    "        row_idx = np.random.randint(len(word2row_idxs[self.vocab[idx]]))\n",
    "        source_fn = df.source_fn[row_idx]\n",
    "        target_fn = df.target_fn[row_idx]\n",
    "        x = normalize_data(prepare_features(source_fn, pad_left=True))\n",
    "        y = normalize_data(prepare_features(target_fn))\n",
    "        return np.stack((x, y)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dss = Datasets(\n",
    "#     vocab*100,\n",
    "#     [lambda word: normalize_data(prepare_features(word, df.source_fn, pad_left=True)),\n",
    "#      lambda word: normalize_data(prepare_features(word, df.target_fn)),\n",
    "#      lambda word: normalize_data(prepare_features(word, df.target_fn))],\n",
    "#     n_inp=2,\n",
    "#     splits = [np.arange(len(vocab)*90), np.arange(len(vocab)*90, len(vocab)*100)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BS = 2048\n",
    "# LR = 1e-3\n",
    "# NUM_WORKERS = 8\n",
    "\n",
    "# train_dl = DataLoader(dss.train, BS, NUM_WORKERS, shuffle=True)\n",
    "# valid_dl = DataLoader(dss.valid, BS, NUM_WORKERS)\n",
    "\n",
    "# dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader as TorchLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2048\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_dl = DataLoader(Dataset(100), BS, NUM_WORKERS, shuffle=True)\n",
    "valid_dl = DataLoader(Dataset(10), BS, NUM_WORKERS)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dls.train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 2, 40, 13])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdl = TorchLoader(Dataset(100), BS, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umount: /dev/shm/: target is busy\r\n",
      "        (In some cases useful info about processes that\r\n",
      "         use the device is found by lsof(8) or fuser(1).)\r\n"
     ]
    }
   ],
   "source": [
    "# Got the following error while training:\n",
    "\n",
    "# DataLoader worker (pid 2073) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n",
    "# trying the solution I found here: https://github.com/pytorch/pytorch/issues/5040\n",
    "# which is to execute\n",
    "!sudo umount /dev/shm/ && sudo mount -t tmpfs -o rw,nosuid,nodev,noexec,relatime,size=50G shm /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unidirectional encoder\n",
    "# teacher_forcing_ratio = 0\n",
    "\n",
    "# class Model(Module):\n",
    "#     def __init__(self, hidden_size=50, hint_n=1):\n",
    "#         self.hint_n = hint_n\n",
    "#         self.encoder= nn.LSTM(\n",
    "#             input_size=13,\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=1,\n",
    "#             batch_first=True,\n",
    "#             dropout=0,\n",
    "#             bidirectional=False\n",
    "#         )\n",
    "#         self.decoder = nn.LSTM(\n",
    "#             input_size=hidden_size+13,\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=1,\n",
    "#             batch_first=True,\n",
    "#             dropout=0,\n",
    "#             bidirectional=False\n",
    "#         )\n",
    "#         self.lin = nn.Linear(hidden_size, 13)\n",
    "            \n",
    "#     def forward(self, source_features, target_features):\n",
    "#         _, (embeddings_dec, _) = self.encoder(source_features)\n",
    "\n",
    "#         outputs = torch.zeros_like(target_features)\n",
    "#         outputs[:, :self.hint_n, :] = target_features[:, :self.hint_n, :]\n",
    "        \n",
    "#         hidden = embeddings_dec\n",
    "#         embeddings_dec = embeddings_dec.squeeze(0)\n",
    "#         cell = torch.zeros_like(embeddings_dec).unsqueeze(0)\n",
    "        \n",
    "#         for t in range(self.hint_n):\n",
    "#             input = torch.cat((outputs[:, t:t+1, :], embeddings_dec.unsqueeze(1)), 2)\n",
    "#             x, (hidden, cell) = self.decoder(input, (hidden, cell))\n",
    "#             x = self.lin(x)\n",
    "#             input = (torch.sigmoid(x) - 0.5) * 16\n",
    "        \n",
    "#         for t in range(self.hint_n, target_features.shape[1]):\n",
    "#             input = torch.cat((input, embeddings_dec.unsqueeze(1)), 2)\n",
    "#             x, (hidden, cell) = self.decoder(input, (hidden, cell))\n",
    "#             x = self.lin(x)\n",
    "#             input = (torch.sigmoid(x) - 0.5) * 16\n",
    "#             outputs[:, t, :] = input.squeeze()\n",
    "            \n",
    "#             if random.random() < teacher_forcing_ratio:\n",
    "#                 input = target_features[:, t, :].unsqueeze(1)\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dl:\n",
    "#     break\n",
    "\n",
    "# model = Model(hint_n=5).cuda()\n",
    "# o = model(batch[0].cuda(), batch[1].cuda())\n",
    "# plt.imshow(o[0][:5, :].detach().cpu())\n",
    "\n",
    "# plt.imshow(batch[1][0][:5, :].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_forcing_ratio = 0\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=50):\n",
    "        self.encoder= nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.lin = nn.Linear(hidden_size, 13)\n",
    "            \n",
    "    def forward(self, source_and_target_features):\n",
    "        source_features = source_and_target_features[:, 0]\n",
    "        target_features = source_and_target_features[:, 1]\n",
    "        _, (embeddings, cell) = self.encoder(source_features)\n",
    "        input = torch.cat(\n",
    "            (\n",
    "                target_features[:, :-1, :],\n",
    "                embeddings.permute(1, 0, 2).repeat(1, target_features.shape[1]-1, 1)\n",
    "            ), 2)\n",
    "#         cell = torch.zeros_like(embeddings)\n",
    "        x, _ = self.decoder(target_features[:, :-1, :], (embeddings, cell))\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_loss = MSELoss()\n",
    "# def modified_MSE(preds, targs):\n",
    "#     mask = targs == 0\n",
    "#     preds[mask] = 0\n",
    "#     return mse_loss(preds, targs)\n",
    "\n",
    "# mse_loss = MSELoss()\n",
    "def targ_trunc_MSE(preds, targs):\n",
    "    return mse_loss(preds, targs[:, 1:, :])\n",
    "\n",
    "learn = Learner(dls.cuda(), Model().cuda(), loss_func=targ_trunc_MSE, lr=1e-3, opt_func=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='449' class='' max='3256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      13.79% [449/3256 00:38<03:58 0.0525]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, cbs=SaveModelCallback(fname='1e-3_SGD', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, cbs=SaveModelCallback(fname='1e-3_SGD', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m(1676)\u001b[0;36mlinear\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1674 \u001b[0;31m        \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1675 \u001b[0;31m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1676 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1677 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1678 \u001b[0;31m            \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> output.shape\n",
      "*** NameError: name 'output' is not defined\n",
      "ipdb> u\n",
      "> \u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m(91)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     89 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     90 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 91 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     92 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     93 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m(722)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    720 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    721 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 722 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    723 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    724 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-650-fc10a01056d0>\u001b[0m(34)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     30 \u001b[0;31m\u001b[0;31m#                 embeddings.permute(1, 0, 2).repeat(1, target_features.shape[1]-1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m\u001b[0;31m#             ), 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;31m#         cell = torch.zeros_like(embeddings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 34 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> x.shape\n",
      "torch.Size([2048, 39, 50])\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd7e71c250>"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "o = learn.model(batch[0].cuda())\n",
    "plt.imshow(o[0][:5, :].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01a566af10>"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[1][0][:5, :].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate embedding for each unique word in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_utterances = df.drop_duplicates(['source_fn'])\n",
    "df_unique_utterances.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetAllUtterances():\n",
    "    def __len__(self):\n",
    "        return df_unique_utterances.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        source_fn = df_unique_utterances.iloc[0].source_fn\n",
    "        target_fn = df_unique_utterances.iloc[0].target_fn\n",
    "        x = normalize_data(prepare_features(source_fn, pad_left=True))\n",
    "        y = normalize_data(prepare_features(target_fn))\n",
    "        return np.stack((x, y)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl = DataLoader(DatasetAllUtterances(), BS, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "self._shutdown_workers()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'self._shutdown_workers()\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    AssertionErrorw.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      ": AssertionErrorException ignored in: can only join a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      ": can only join a child process\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "Exception ignored in:     Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "        w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)self._shutdown_workers()\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "        assert self._parent_pid == os.getpid(), 'can only join a child process'w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)Traceback (most recent call last):\n",
      "\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "AssertionError  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "        : self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only join a child process'can only join a child process\n",
      "\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "AssertionError:     can only join a child processw.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "AssertionError    : self._shutdown_workers()can only join a child process\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f022ed43050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1075, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 55s, sys: 24.9 s, total: 8min 20s\n",
      "Wall time: 6min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_embeddings = []\n",
    "with torch.no_grad():\n",
    "    learn.model.train = False\n",
    "    for batch in all_dl:\n",
    "        _, (embeddings, _) = learn.model.encoder(batch[0][:, 0].cuda())\n",
    "        all_embeddings.append(embeddings.view(embeddings.shape[1], -1).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in all_dl:\n",
    "        outputs = learn.model(batch[0].cuda())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efeb5d7f650>"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[-1].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][-1].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efea6dfdf90>"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[-10].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][-10].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efede4391d0>"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[0].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][0].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# word2row_idxs_unique_utterances = defaultdict(empty_list)\n",
    "\n",
    "# for idx, row in df_unique_utterances.iterrows():\n",
    "#     word2row_idxs_unique_utterances[row.source_word].append(idx)\n",
    "    \n",
    "# pd.to_pickle(word2row_idxs_unique_utterances, 'word2row_idxs_unique_utterances.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2row_idxs_unique_utterances = pd.read_pickle('word2row_idxs_unique_utterances.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2embedding = {}\n",
    "\n",
    "for k, v in word2row_idxs_unique_utterances.items():\n",
    "    word2embedding[k] = all_embeddings[np.array(v)].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered rows with nan values: 1\n"
     ]
    }
   ],
   "source": [
    "word2embedding_without_nans= {}\n",
    "nans_encountered = 0\n",
    "for k, v in word2embedding.items():\n",
    "    if k in vocab and k == k and (not np.isnan(v.numpy()).any()):\n",
    "        word2embedding_without_nans[k] = v.numpy()\n",
    "    else: nans_encountered += 1\n",
    "\n",
    "print(f'Encountered rows with nan values: {nans_encountered}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating embeddings using [word-embeddings-benchmarks](https://github.com/kudkudak/word-embeddings-benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_WS353, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "from web.embedding import Embedding, Vocabulary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MEN\": fetch_MEN(),\n",
    "    \"WS353\": fetch_WS353(),\n",
    "    \"SIMLEX999\": fetch_SimLex999()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_embeddings = Embedding(\n",
    "    Vocabulary([w.lower() for w in list(word2embedding_without_nans.keys())]),\n",
    "    np.array(list(word2embedding_without_nans.values()))\n",
    ")\n",
    "\n",
    "speech2vec = KeyedVectors.load_word2vec_format('../speech2vec-pretrained-vectors/speech2vec/50.vec', binary=False) \n",
    "speech2vec_embeddings = Embedding(Vocabulary(list(speech2vec.vocab.keys())), speech2vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 392 words. Will replace them with mean vector\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:336: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A = np.vstack(w.get(word, mean_vector) for word in X[:, 0])\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  B = np.vstack(w.get(word, mean_vector) for word in X[:, 1])\n",
      "Missing 61 words. Will replace them with mean vector\n",
      "Missing 24 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.5896756323911225\n",
      "Spearman correlation of scores on WS353 0.49890235673392536\n",
      "Spearman correlation of scores on SIMLEX999 0.28202624769092116\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(speech2vec_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 242 words. Will replace them with mean vector\n",
      "Missing 49 words. Will replace them with mean vector\n",
      "Missing 11 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.016336071418511844\n",
      "Spearman correlation of scores on WS353 -0.019580171882017928\n",
      "Spearman correlation of scores on SIMLEX999 -0.022798757099223497\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(our_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from IPython.lib.display import Audio\n",
    "\n",
    "# row = df.sample(1)\n",
    "# print(row.target_word)\n",
    "# Audio(f'data/examples_audio/{row.target_fn.item()}.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
