{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import MSELoss\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 2.42 s, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4140463, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv('data/examples.csv', converters={'target_fns':ast.literal_eval})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While attempting to train the model, it turned out that the reading and unpickling operation done at this scale, with so many files, is very computationally expensive.\n",
    "\n",
    "But the examples in the mfcc represenatations are very small. Let's read them all into the memory before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# all_fns = []\n",
    "# for l in df.target_fns:\n",
    "#     all_fns += l\n",
    "# all_fns += df.source_fn.values.tolist()    \n",
    "\n",
    "# fn2features = {}\n",
    "# for fn in set(all_fns):\n",
    "#     ary = pd.read_pickle(f'data/examples/{fn}.pkl')\n",
    "#     fn2features[fn] = ary\n",
    "\n",
    "# pd.to_pickle(fn2features, 'data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 11.5 s, total: 28.5 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn2features = pd.read_pickle('data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4688767"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fn2features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc740a7ef90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fn2features[list(fn2features.keys())[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect that reading the data from a file saved within numpy (`numpy.save`) is much less computationally expensive than unpickling it, but I might be wrong. Either way, at ~4 million of unique utterances, the dataset is small enough to comfortably fit within memory of a GCP instance (at ~53GBs used RAM during training).\n",
    "\n",
    "This might not be ideal for experimentation on home rigs. Saving the data using `numpy.save` and evaluating performance would definitely be a very interesting and useful exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_fn</th>\n",
       "      <th>target_fns</th>\n",
       "      <th>set_name</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>audio_fpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THAT</td>\n",
       "      <td>['I', 'FELT', 'IT', 'WAS']</td>\n",
       "      <td>8e6739008aaa44feae36b2c3d9c8c44e</td>\n",
       "      <td>[6b23b5c2091b4899b73f8691a9bb3bb9, e717579ac2e04163aa7afe440af37705, 4d18cbcd200c4dd59efa56ba59d6e46b, dee9407548754f009db42e86a4ff5f23]</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IT</td>\n",
       "      <td>['FELT', 'THAT', 'WAS', 'TIME']</td>\n",
       "      <td>4d18cbcd200c4dd59efa56ba59d6e46b</td>\n",
       "      <td>[e717579ac2e04163aa7afe440af37705, 8e6739008aaa44feae36b2c3d9c8c44e, dee9407548754f009db42e86a4ff5f23, 525d4e83b9b548dbaef7d35a77df1afc]</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAS</td>\n",
       "      <td>['THAT', 'IT', 'TIME', 'TO']</td>\n",
       "      <td>dee9407548754f009db42e86a4ff5f23</td>\n",
       "      <td>[8e6739008aaa44feae36b2c3d9c8c44e, 4d18cbcd200c4dd59efa56ba59d6e46b, 525d4e83b9b548dbaef7d35a77df1afc, 9e1c98df449f48d2aa09db0dcebc7cf4]</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIME</td>\n",
       "      <td>['IT', 'WAS', 'TO', 'INTRODUCE']</td>\n",
       "      <td>525d4e83b9b548dbaef7d35a77df1afc</td>\n",
       "      <td>[4d18cbcd200c4dd59efa56ba59d6e46b, dee9407548754f009db42e86a4ff5f23, 9e1c98df449f48d2aa09db0dcebc7cf4, c342b93295d644e088fa7ab14465a5b8]</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TO</td>\n",
       "      <td>['WAS', 'TIME', 'INTRODUCE', 'MYSELF']</td>\n",
       "      <td>9e1c98df449f48d2aa09db0dcebc7cf4</td>\n",
       "      <td>[dee9407548754f009db42e86a4ff5f23, 525d4e83b9b548dbaef7d35a77df1afc, c342b93295d644e088fa7ab14465a5b8, 390a5367ec794ed1b73c3ffce4c3aad9]</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_word                             target_word  \\\n",
       "0        THAT              ['I', 'FELT', 'IT', 'WAS']   \n",
       "1          IT         ['FELT', 'THAT', 'WAS', 'TIME']   \n",
       "2         WAS            ['THAT', 'IT', 'TIME', 'TO']   \n",
       "3        TIME        ['IT', 'WAS', 'TO', 'INTRODUCE']   \n",
       "4          TO  ['WAS', 'TIME', 'INTRODUCE', 'MYSELF']   \n",
       "\n",
       "                          source_fn  \\\n",
       "0  8e6739008aaa44feae36b2c3d9c8c44e   \n",
       "1  4d18cbcd200c4dd59efa56ba59d6e46b   \n",
       "2  dee9407548754f009db42e86a4ff5f23   \n",
       "3  525d4e83b9b548dbaef7d35a77df1afc   \n",
       "4  9e1c98df449f48d2aa09db0dcebc7cf4   \n",
       "\n",
       "                                                                                                                                 target_fns  \\\n",
       "0  [6b23b5c2091b4899b73f8691a9bb3bb9, e717579ac2e04163aa7afe440af37705, 4d18cbcd200c4dd59efa56ba59d6e46b, dee9407548754f009db42e86a4ff5f23]   \n",
       "1  [e717579ac2e04163aa7afe440af37705, 8e6739008aaa44feae36b2c3d9c8c44e, dee9407548754f009db42e86a4ff5f23, 525d4e83b9b548dbaef7d35a77df1afc]   \n",
       "2  [8e6739008aaa44feae36b2c3d9c8c44e, 4d18cbcd200c4dd59efa56ba59d6e46b, 525d4e83b9b548dbaef7d35a77df1afc, 9e1c98df449f48d2aa09db0dcebc7cf4]   \n",
       "3  [4d18cbcd200c4dd59efa56ba59d6e46b, dee9407548754f009db42e86a4ff5f23, 9e1c98df449f48d2aa09db0dcebc7cf4, c342b93295d644e088fa7ab14465a5b8]   \n",
       "4  [dee9407548754f009db42e86a4ff5f23, 525d4e83b9b548dbaef7d35a77df1afc, c342b93295d644e088fa7ab14465a5b8, 390a5367ec794ed1b73c3ffce4c3aad9]   \n",
       "\n",
       "          set_name  speaker_id  book_id  \\\n",
       "0  train-clean-360        7000    83696   \n",
       "1  train-clean-360        7000    83696   \n",
       "2  train-clean-360        7000    83696   \n",
       "3  train-clean-360        7000    83696   \n",
       "4  train-clean-360        7000    83696   \n",
       "\n",
       "                                                        audio_fpath  \n",
       "0  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "1  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "2  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "3  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "4  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = df[df.set_name.isin(['train-clean-360', 'train-clean-100', 'dev-clean'])]\n",
    "valid_examples = df[df.set_name == 'test-clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32786448, 337256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples.size, valid_examples.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.32 s, sys: 120 ms, total: 4.44 s\n",
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_fns = df.source_fn.unique()\n",
    "np.random.shuffle(unique_fns)\n",
    "lengths = []\n",
    "for i, features in enumerate(fn2features.values()):\n",
    "    lengths.append(features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.019326189593126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# for k, feature in fn2features.items():\n",
    "#     features.append(feature.reshape((1, -1)))\n",
    "\n",
    "# big_ary = np.concatenate(features, 1)\n",
    "\n",
    "# big_ary.mean()\n",
    "\n",
    "# big_ary.std()\n",
    "\n",
    "# abs(normalize_data(big_ary)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc54d451b10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean = -5\n",
    "dataset_std = 15\n",
    "\n",
    "def normalize_data(ary):\n",
    "    return (ary - dataset_mean) / dataset_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_source(fn, pad_to=max(lengths)):\n",
    "    ary = fn2features[fn]\n",
    "    example = np.zeros((pad_to, 13))\n",
    "    example[-ary.shape[0]:, :] = ary # padding from the left\n",
    "    return example.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_target(fns, pad_to=max(lengths)):\n",
    "    features = []\n",
    "    for fn in fns:\n",
    "        ary = fn2features[fn]\n",
    "        ary_zeros = np.zeros((pad_to, 13))\n",
    "        ary_zeros[:ary.shape[0], :] = ary\n",
    "        features.append(ary_zeros)\n",
    "    return np.concatenate(features, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = Datasets(\n",
    "    df,\n",
    "    [lambda row: normalize_data(prepare_features_source(row.source_fn)),\n",
    "     lambda row: normalize_data(prepare_features_target(row.target_fns)),\n",
    "     lambda row: normalize_data(prepare_features_target(row.target_fns))],\n",
    "    n_inp=2,\n",
    "    splits = [train_examples.index, valid_examples.index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2048\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 6\n",
    "\n",
    "train_dl = DataLoader(dss.train, BS, NUM_WORKERS, shuffle=True)\n",
    "valid_dl = DataLoader(dss.valid, BS, NUM_WORKERS)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got the following error while training:\n",
    "\n",
    "# DataLoader worker (pid 2073) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n",
    "# trying the solution I found here: https://github.com/pytorch/pytorch/issues/5040\n",
    "# which is to execute\n",
    "\n",
    "!sudo umount /dev/shm/ && sudo mount -t tmpfs -o rw,nosuid,nodev,noexec,relatime,size=75G shm /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=50):\n",
    "        self.encoder= nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=4*13+2*hidden_size,\n",
    "            hidden_size=2*hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.lin = nn.Linear(2*hidden_size, 4*13)\n",
    "            \n",
    "    def forward(self, source_features, target_features):\n",
    "        _, (embeddings_dec, _) = self.encoder(source_features)\n",
    "        embeddings_dec = embeddings_dec.view(embeddings_dec.shape[1], -1)\n",
    "        \n",
    "        outputs = torch.zeros_like(target_features)\n",
    "        input = target_features[:, :1, :]\n",
    "        outputs[:, 0, :] = input.squeeze()\n",
    "    \n",
    "        hidden = embeddings_dec.unsqueeze(0)\n",
    "        cell = torch.zeros_like(embeddings_dec).unsqueeze(0)\n",
    "        for t in range(1, target_features.shape[1]):\n",
    "            input = torch.cat((input, embeddings_dec.unsqueeze(1)), 2)\n",
    "            x, (hidden, cell) = self.decoder(input, (hidden, cell))\n",
    "            x = self.lin(x)\n",
    "            input = torch.sigmoid(x) * 25\n",
    "            outputs[:, t, :] = input.squeeze()\n",
    "            \n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                input = target_features[:, t, :].unsqueeze(1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dl: break\n",
    "# model = Model().cuda()\n",
    "# out = model(batch[0].cuda(), batch[1].cuda())\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_loss = MSELoss()\n",
    "# def modified_MSE(preds, targs):\n",
    "#     mask = targs == 0\n",
    "#     preds[mask] = 0\n",
    "#     return mse_loss(preds, targs)\n",
    "\n",
    "learn = Learner(dls.cuda(), Model().cuda(), loss_func=MSELoss(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(4, cbs=SaveModelCallback(fname='4epochs_1e-3_adam', every_epoch=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fc54d4f9cd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('30epochs_1e-4_adam_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.095774</td>\n",
       "      <td>0.098241</td>\n",
       "      <td>19:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.098242</td>\n",
       "      <td>19:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.095701</td>\n",
       "      <td>0.098238</td>\n",
       "      <td>19:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.098236</td>\n",
       "      <td>19:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095845</td>\n",
       "      <td>0.098216</td>\n",
       "      <td>19:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.095553</td>\n",
       "      <td>0.098215</td>\n",
       "      <td>19:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.095875</td>\n",
       "      <td>0.098213</td>\n",
       "      <td>19:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095716</td>\n",
       "      <td>0.098210</td>\n",
       "      <td>19:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095853</td>\n",
       "      <td>0.098205</td>\n",
       "      <td>19:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>0.098201</td>\n",
       "      <td>19:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, cbs=SaveModelCallback(fname='10epochs_1e-4_adam', every_epoch=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.102997</td>\n",
       "      <td>19:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.100390</td>\n",
       "      <td>0.102725</td>\n",
       "      <td>19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>0.102259</td>\n",
       "      <td>19:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099473</td>\n",
       "      <td>0.101924</td>\n",
       "      <td>19:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.099239</td>\n",
       "      <td>0.101716</td>\n",
       "      <td>19:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.098808</td>\n",
       "      <td>0.101360</td>\n",
       "      <td>19:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.100963</td>\n",
       "      <td>19:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098399</td>\n",
       "      <td>0.100753</td>\n",
       "      <td>19:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>0.100603</td>\n",
       "      <td>19:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.098022</td>\n",
       "      <td>0.100483</td>\n",
       "      <td>19:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.097691</td>\n",
       "      <td>0.100264</td>\n",
       "      <td>19:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.097677</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>19:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.097494</td>\n",
       "      <td>0.099964</td>\n",
       "      <td>19:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.097436</td>\n",
       "      <td>0.099798</td>\n",
       "      <td>19:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.097188</td>\n",
       "      <td>0.099588</td>\n",
       "      <td>19:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.097167</td>\n",
       "      <td>0.099419</td>\n",
       "      <td>19:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.096822</td>\n",
       "      <td>0.099256</td>\n",
       "      <td>19:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.096691</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>19:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.096661</td>\n",
       "      <td>0.099034</td>\n",
       "      <td>19:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.096506</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>19:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.096525</td>\n",
       "      <td>0.098791</td>\n",
       "      <td>19:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.096165</td>\n",
       "      <td>0.098727</td>\n",
       "      <td>19:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.096194</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>19:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.096123</td>\n",
       "      <td>0.098569</td>\n",
       "      <td>19:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.096175</td>\n",
       "      <td>0.098520</td>\n",
       "      <td>20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.096118</td>\n",
       "      <td>0.098516</td>\n",
       "      <td>19:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.095925</td>\n",
       "      <td>0.098517</td>\n",
       "      <td>20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.095892</td>\n",
       "      <td>0.098380</td>\n",
       "      <td>19:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.095756</td>\n",
       "      <td>0.098358</td>\n",
       "      <td>20:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>0.098302</td>\n",
       "      <td>19:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(30, cbs=SaveModelCallback(fname='30epochs_1e-4_adam', every_epoch=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.267969</td>\n",
       "      <td>21.719009</td>\n",
       "      <td>18:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.549919</td>\n",
       "      <td>21.043291</td>\n",
       "      <td>18:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20.231981</td>\n",
       "      <td>20.744255</td>\n",
       "      <td>18:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.119682</td>\n",
       "      <td>20.591694</td>\n",
       "      <td>18:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(4, cbs=SaveModelCallback(fname='4epochs_1e-3_adam', every_epoch=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate embedding for each unique word in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_utterances = df.drop_duplicates(['source_fn'])\n",
    "df_unique_utterances.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss_all_utterances = Datasets(\n",
    "    df_unique_utterances,\n",
    "    [lambda row: prepare_features_source(row.source_fn), lambda row: 0],\n",
    "    n_inp=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl = DataLoader(dss_all_utterances, BS, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.6 s, sys: 16.8 s, total: 1min 13s\n",
      "Wall time: 6min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_embeddings = []\n",
    "with torch.no_grad():\n",
    "    learn.model.train = False\n",
    "    for batch in all_dl:\n",
    "        _, (embeddings, _) = learn.model.encoder(batch[0].cuda())\n",
    "        all_embeddings.append(embeddings.view(embeddings.shape[1], -1).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4140463, 100])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 12s, sys: 1.16 s, total: 6min 13s\n",
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2row_idxs = defaultdict(lambda: list())\n",
    "\n",
    "for idx, row in df_unique_utterances.iterrows():\n",
    "    word2row_idxs[row.source_word].append(idx)\n",
    "    \n",
    "word2embedding = {}\n",
    "\n",
    "for k, v in word2row_idxs.items():\n",
    "    word2embedding[k] = all_embeddings[np.array(v)].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered rows with nan values: 1\n"
     ]
    }
   ],
   "source": [
    "word2embedding_without_nans= {}\n",
    "nans_encountered = 0\n",
    "for k, v in word2embedding.items():\n",
    "    if k == k and (not np.isnan(v.numpy()).any()):\n",
    "        word2embedding_without_nans[k] = v.numpy()\n",
    "    else: nans_encountered += 1\n",
    "\n",
    "print(f'Encountered rows with nan values: {nans_encountered}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating embeddings using [word-embeddings-benchmarks](https://github.com/kudkudak/word-embeddings-benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_WS353, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "from web.embedding import Embedding, Vocabulary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MEN\": fetch_MEN(),\n",
    "    \"WS353\": fetch_WS353(),\n",
    "    \"SIMLEX999\": fetch_SimLex999()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_embeddings = Embedding(\n",
    "    Vocabulary([w.lower() for w in list(word2embedding_without_nans.keys())]),\n",
    "    np.array(list(word2embedding_without_nans.values()))\n",
    ")\n",
    "\n",
    "speech2vec = KeyedVectors.load_word2vec_format('../speech2vec-pretrained-vectors/speech2vec/50.vec', binary=False) \n",
    "speech2vec_embeddings = Embedding(Vocabulary(list(speech2vec.vocab.keys())), speech2vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 392 words. Will replace them with mean vector\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:336: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A = np.vstack(w.get(word, mean_vector) for word in X[:, 0])\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  B = np.vstack(w.get(word, mean_vector) for word in X[:, 1])\n",
      "Missing 61 words. Will replace them with mean vector\n",
      "Missing 24 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.5896756323911225\n",
      "Spearman correlation of scores on WS353 0.49890235673392536\n",
      "Spearman correlation of scores on SIMLEX999 0.28202624769092116\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(speech2vec_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 272 words. Will replace them with mean vector\n",
      "Missing 50 words. Will replace them with mean vector\n",
      "Missing 13 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.06259137465776407\n",
      "Spearman correlation of scores on WS353 -0.0019761465593389834\n",
      "Spearman correlation of scores on SIMLEX999 -0.1537255764052225\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(our_embeddings, data.X, data.y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
