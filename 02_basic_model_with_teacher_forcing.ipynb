{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 2.54 s, total: 30.1 s\n",
      "Wall time: 30.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17937758, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv('data/examples.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While attempting to train the model, it turned out that the reading and unpickling operation done at this scale, with so many files, is very computationally expensive.\n",
    "\n",
    "But the examples in the mfcc represenatations are very small. Let's read them all into the memory before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniq_fns = np.unique(df.target_fn.values)\n",
    "\n",
    "# %%time\n",
    "\n",
    "# fn2feature = {}\n",
    "# for fn in uniq_fns:\n",
    "#     ary = pd.read_pickle(f'data/examples/{fn}.pkl')\n",
    "#     fn2feature[fn] = ary\n",
    "\n",
    "# pd.to_pickle(fn2feature, 'data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 s, sys: 10.9 s, total: 27.5 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn2features = pd.read_pickle('data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect that reading the data from a file saved within numpy (`numpy.save`) is much less computationally expensive than unpickling it, but I might be wrong. Either way, at ~4 million of unique utterances, the dataset is small enough to comfortably fit within memory of a GCP instance (at ~53GBs used RAM during training).\n",
    "\n",
    "This might not be ideal for experimentation on home rigs. Saving the data using `numpy.save` and evaluating performance would definitely be a very interesting and useful exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_fn</th>\n",
       "      <th>target_fn</th>\n",
       "      <th>set_name</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>distance_from_target</th>\n",
       "      <th>audio_fpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>FELT</td>\n",
       "      <td>43a14fe66b6348718f089ec553bf57b1</td>\n",
       "      <td>b6c1288c07504236a2b054c972a6e92f</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>THAT</td>\n",
       "      <td>43a14fe66b6348718f089ec553bf57b1</td>\n",
       "      <td>ed9ceac76f7e49e7809ec56db40d37a2</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>2</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FELT</td>\n",
       "      <td>I</td>\n",
       "      <td>b6c1288c07504236a2b054c972a6e92f</td>\n",
       "      <td>43a14fe66b6348718f089ec553bf57b1</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FELT</td>\n",
       "      <td>THAT</td>\n",
       "      <td>b6c1288c07504236a2b054c972a6e92f</td>\n",
       "      <td>ed9ceac76f7e49e7809ec56db40d37a2</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FELT</td>\n",
       "      <td>IT</td>\n",
       "      <td>b6c1288c07504236a2b054c972a6e92f</td>\n",
       "      <td>235da027aeac418da43430e1f3470da4</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>2</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_word target_word                         source_fn  \\\n",
       "0           I        FELT  43a14fe66b6348718f089ec553bf57b1   \n",
       "1           I        THAT  43a14fe66b6348718f089ec553bf57b1   \n",
       "2        FELT           I  b6c1288c07504236a2b054c972a6e92f   \n",
       "3        FELT        THAT  b6c1288c07504236a2b054c972a6e92f   \n",
       "4        FELT          IT  b6c1288c07504236a2b054c972a6e92f   \n",
       "\n",
       "                          target_fn         set_name  speaker_id  book_id  \\\n",
       "0  b6c1288c07504236a2b054c972a6e92f  train-clean-360        7000    83696   \n",
       "1  ed9ceac76f7e49e7809ec56db40d37a2  train-clean-360        7000    83696   \n",
       "2  43a14fe66b6348718f089ec553bf57b1  train-clean-360        7000    83696   \n",
       "3  ed9ceac76f7e49e7809ec56db40d37a2  train-clean-360        7000    83696   \n",
       "4  235da027aeac418da43430e1f3470da4  train-clean-360        7000    83696   \n",
       "\n",
       "   distance_from_target  \\\n",
       "0                     1   \n",
       "1                     2   \n",
       "2                     1   \n",
       "3                     1   \n",
       "4                     2   \n",
       "\n",
       "                                                        audio_fpath  \n",
       "0  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "1  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "2  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "3  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "4  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = df[df.set_name.isin(['train-clean-360', 'train-clean-100', 'dev-clean'])]\n",
    "valid_examples = df[df.set_name == 'test-clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159688530, 1751292)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples.size, valid_examples.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.42 s, sys: 196 ms, total: 5.62 s\n",
      "Wall time: 5.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_fns = df.source_fn.unique()\n",
    "np.random.shuffle(unique_fns)\n",
    "lengths = []\n",
    "for i, features in enumerate(fn2features.values()):\n",
    "    lengths.append(features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.028019713968394"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f52b5110750>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(fn, pad_to=max(lengths), pad_left=False):\n",
    "    ary = fn2features[fn]\n",
    "    example = np.zeros((pad_to, 13))\n",
    "    if pad_left:\n",
    "        example[-ary.shape[0]:, :] = ary\n",
    "    else: example[:ary.shape[0], :] = ary\n",
    "    return example.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = Datasets(\n",
    "    df,\n",
    "    [lambda row: prepare_features(row.source_fn, pad_left=True),\n",
    "     lambda row: prepare_features(row.target_fn),\n",
    "     lambda row: prepare_features(row.target_fn)],\n",
    "    n_inp=2,\n",
    "    splits = [train_examples.index, valid_examples.index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2048\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "train_dl = DataLoader(dss.train, BS, NUM_WORKERS, shuffle=True)\n",
    "valid_dl = DataLoader(dss.valid, BS, NUM_WORKERS)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got the following error while training:\n",
    "\n",
    "# DataLoader worker (pid 2073) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n",
    "# trying the solution I found here: https://github.com/pytorch/pytorch/issues/5040\n",
    "# which is to execute `sudo umount /dev/shm/ && sudo mount -t tmpfs -o rw,nosuid,nodev,noexec,relatime,size=50G shm /dev/shm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=50):\n",
    "        self.encoder= nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=13+hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.lin = nn.Linear(2*hidden_size, 13)\n",
    "            \n",
    "    def forward(self, source_features, target_features):\n",
    "        _, (embeddings_dec, _) = self.encoder(source_features)\n",
    "        embeddings_bi = torch.cat((embeddings_dec, embeddings_dec))\n",
    "        embeddings_dec = embeddings_dec.permute(1,0,2)\n",
    "        \n",
    "        outputs = torch.zeros_like(target_features)\n",
    "        input = target_features[:, :1, :]\n",
    "        hidden = embeddings_bi\n",
    "        cell = torch.zeros_like(embeddings_bi)\n",
    "        for t in range(target_features.shape[1]):\n",
    "            input = torch.cat((input, embeddings_dec), 2)\n",
    "            x, (hidden, cell) = self.decoder(input, (hidden, cell))\n",
    "            input = self.lin(x)\n",
    "            outputs[:, t, :] = input.squeeze()\n",
    "            \n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                input = target_features[:, t, :].unsqueeze(1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_loss = MSELoss()\n",
    "# def modified_MSE(preds, targs):\n",
    "#     mask = targs == 0\n",
    "#     preds[mask] = 0\n",
    "#     return mse_loss(preds, targs)\n",
    "\n",
    "learn = Learner(dls.cuda(), Model().cuda(), loss_func=MSELoss(), lr=1e-3, opt_func=SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25.405891</td>\n",
       "      <td>26.041719</td>\n",
       "      <td>1:19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.271435</td>\n",
       "      <td>24.791180</td>\n",
       "      <td>1:20:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23.041260</td>\n",
       "      <td>23.634680</td>\n",
       "      <td>1:20:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22.733116</td>\n",
       "      <td>23.289080</td>\n",
       "      <td>1:22:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22.438246</td>\n",
       "      <td>23.022280</td>\n",
       "      <td>1:23:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22.109318</td>\n",
       "      <td>22.689079</td>\n",
       "      <td>1:22:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>21.932486</td>\n",
       "      <td>22.432524</td>\n",
       "      <td>1:21:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>21.707077</td>\n",
       "      <td>22.249060</td>\n",
       "      <td>1:22:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>21.510958</td>\n",
       "      <td>22.059782</td>\n",
       "      <td>1:22:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>21.411123</td>\n",
       "      <td>21.901356</td>\n",
       "      <td>1:22:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>21.223747</td>\n",
       "      <td>21.753426</td>\n",
       "      <td>1:22:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>21.082430</td>\n",
       "      <td>21.633358</td>\n",
       "      <td>1:22:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20.972805</td>\n",
       "      <td>21.523254</td>\n",
       "      <td>1:22:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20.923931</td>\n",
       "      <td>21.434881</td>\n",
       "      <td>1:22:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20.902357</td>\n",
       "      <td>21.342955</td>\n",
       "      <td>1:22:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>20.758535</td>\n",
       "      <td>21.281099</td>\n",
       "      <td>1:22:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(16, cbs=SaveModelCallback(fname='16epochs_1e-3_SGD', every_epoch=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate embedding for each unique word in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_utterances = df.drop_duplicates(['source_fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss_all_utterances = Datasets(\n",
    "    df_unique_utterances,\n",
    "    [lambda row: prepare_features(row.source_fn, pad_left=True), lambda row: 0],\n",
    "    n_inp=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl = DataLoader(dss_all_utterances, BS, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.9 s, sys: 20.3 s, total: 1min 5s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_embeddings = []\n",
    "with torch.no_grad():\n",
    "    learn.model.train = False\n",
    "    for batch in all_dl:\n",
    "        _, (embeddings, _) = learn.model.encoder(batch[0].cuda())\n",
    "        all_embeddings.append(embeddings.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_utterances.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 59s, sys: 1.22 s, total: 7min\n",
      "Wall time: 6min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2row_idxs = defaultdict(lambda: list())\n",
    "\n",
    "for idx, row in df_unique_utterances.iterrows():\n",
    "    word2row_idxs[row.source_word].append(idx)\n",
    "    \n",
    "word2embedding = {}\n",
    "\n",
    "for k, v in word2row_idxs.items():\n",
    "    word2embedding[k] = all_embeddings[np.array(v)].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered rows with nan values: 1\n"
     ]
    }
   ],
   "source": [
    "word2embedding_without_nans= {}\n",
    "nans_encountered = 0\n",
    "for k, v in word2embedding.items():\n",
    "    if k == k and (not np.isnan(v.numpy()).any()):\n",
    "        word2embedding_without_nans[k] = v.numpy()\n",
    "    else: nans_encountered += 1\n",
    "\n",
    "print(f'Encountered rows with nan values: {nans_encountered}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating embeddings using [word-embeddings-benchmarks](https://github.com/kudkudak/word-embeddings-benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_WS353, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "from web.embedding import Embedding, Vocabulary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MEN\": fetch_MEN(),\n",
    "    \"WS353\": fetch_WS353(),\n",
    "    \"SIMLEX999\": fetch_SimLex999()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_embeddings = Embedding(\n",
    "    Vocabulary([w.lower() for w in list(word2embedding_without_nans.keys())]),\n",
    "    np.array(list(word2embedding_without_nans.values()))\n",
    ")\n",
    "\n",
    "speech2vec = KeyedVectors.load_word2vec_format('../speech2vec-pretrained-vectors/speech2vec/50.vec', binary=False) \n",
    "speech2vec_embeddings = Embedding(Vocabulary(list(speech2vec.vocab.keys())), speech2vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 392 words. Will replace them with mean vector\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:336: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A = np.vstack(w.get(word, mean_vector) for word in X[:, 0])\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  B = np.vstack(w.get(word, mean_vector) for word in X[:, 1])\n",
      "Missing 61 words. Will replace them with mean vector\n",
      "Missing 24 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.5896756323911225\n",
      "Spearman correlation of scores on WS353 0.49890235673392536\n",
      "Spearman correlation of scores on SIMLEX999 0.28202624769092116\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(speech2vec_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 242 words. Will replace them with mean vector\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:336: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A = np.vstack(w.get(word, mean_vector) for word in X[:, 0])\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  B = np.vstack(w.get(word, mean_vector) for word in X[:, 1])\n",
      "Missing 49 words. Will replace them with mean vector\n",
      "Missing 11 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.05025891129376428\n",
      "Spearman correlation of scores on WS353 -0.024967348979964638\n",
      "Spearman correlation of scores on SIMLEX999 -0.001284136642627865\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(our_embeddings, data.X, data.y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
