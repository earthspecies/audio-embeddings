{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the ebooks [here](https://www.openslr.org/resources/12/original-books.tar.gz).\n",
    "\n",
    "We will need the pretrained embeddings from https://github.com/iamyuanchung/speech2vec-pretrained-vectors. We will use them to compare our results and also to figure out what vocab the authors of the speech2vec paper used for training. Let us start with the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_WS353, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "from web.embedding import Embedding, Vocabulary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech2vec = KeyedVectors.load_word2vec_format('../speech2vec-pretrained-vectors/speech2vec/50.vec', binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37622"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(speech2vec.vocab.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_lines = {\n",
    "    '1004/1004.txt.utf-8': 535,\n",
    "    '10123/10123.txt.utf-8': 85,\n",
    "    '10359/10359.txt.utf-8': 76,\n",
    "    '10360/10360.txt.utf-8': 57,\n",
    "    '10378/10378.txt.utf-8': 96,\n",
    "    '10390/10390.txt.utf-8': 89,\n",
    "    '1193/1193.txt.utf-8': 272,\n",
    "    '12441/12441-0.txt': 101,\n",
    "    '1249/1249.txt.utf-8': 614,\n",
    "    '1325/1325.txt.utf-8': 434,\n",
    "    '1674/1674.txt.utf-8': 360,\n",
    "    '2046/2046.txt.utf-8': 295,\n",
    "    '2147/2147.txt.utf-8': 66,\n",
    "    '2184/2184.txt.utf-8': 302,\n",
    "    '2383/2383.txt.utf-8': 408,\n",
    "    '2486/2486.txt.utf-8': 293,\n",
    "    '2488/2488.txt.utf-8': 495,\n",
    "    '2512/2512-0.txt': 113,\n",
    "    '2515/2515.txt.utf-8': 281,\n",
    "    '2678/2678.txt.utf-8': 305,\n",
    "    '2679/2679.txt.utf-8': 308,\n",
    "    '269/269-0.txt': 67,\n",
    "    '282/282-0.txt': 43,\n",
    "    '2891/2891.txt.utf-8': 336,\n",
    "    '3053/3053.txt.utf-8': 340,\n",
    "    '3169/3169.txt.utf-8': 386,\n",
    "    '325/325.txt.utf-8': 170,\n",
    "    '3300/3300.txt.utf-8': 40,\n",
    "    '34757/34757-0.txt': 185,\n",
    "    '3604/3604.txt.utf-8': 612,\n",
    "    '3623/3623.txt.utf-8': 342,\n",
    "    '3697/3697.txt.utf-8': 449,\n",
    "    '37660/37660-0.txt': 74,\n",
    "    '4028/4028.txt.utf-8': 402,\n",
    "    '4042/4042.txt.utf-8': 438,\n",
    "    '435/435.txt.utf-8': 62,\n",
    "    '6456/6456.txt.utf-8': 53,\n",
    "    '7098/7098.txt.utf-8': 77,\n",
    "    '76/76.txt.utf-8': 579,\n",
    "    '778/778.txt.utf-8': 297,\n",
    "    '786/786-0.txt': 158,\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 472 ms, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_pairs = []\n",
    "\n",
    "for fn, starting_line in starting_lines.items():\n",
    "    with open(f'data/books/LibriSpeech/books/utf-8/{fn}') as file:\n",
    "        out = []\n",
    "        for i, line in enumerate(file.readlines()):\n",
    "            if i < starting_line: continue\n",
    "            line = line.strip()\n",
    "            toks = []\n",
    "\n",
    "            for tok in line.split():\n",
    "                tok = tok.lower()\n",
    "                if tok in vocab:\n",
    "                    toks.append(tok)\n",
    "                else:\n",
    "                    toks.append('<UNK>')\n",
    "            out += toks\n",
    "\n",
    "        for i, word in enumerate(out):\n",
    "            if word is '<UNK>': continue\n",
    "            for offset in [-2, -1, 1, 2]:\n",
    "                if i + offset < 0 or i + offset >= len(out): continue\n",
    "                target_word = out[i+offset]\n",
    "                if target_word is '<UNK>': continue\n",
    "                word_pairs.append([word, target_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['midway', 'upon'],\n",
       " ['midway', 'the'],\n",
       " ['upon', 'midway'],\n",
       " ['upon', 'the'],\n",
       " ['upon', 'journey'],\n",
       " ['the', 'midway'],\n",
       " ['the', 'upon'],\n",
       " ['the', 'journey'],\n",
       " ['the', 'of'],\n",
       " ['journey', 'upon'],\n",
       " ['journey', 'the'],\n",
       " ['journey', 'of'],\n",
       " ['journey', 'our'],\n",
       " ['of', 'the'],\n",
       " ['of', 'journey'],\n",
       " ['of', 'our'],\n",
       " ['of', 'life'],\n",
       " ['our', 'journey'],\n",
       " ['our', 'of'],\n",
       " ['our', 'life']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10140726"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(vocab)\n",
    "np.random.shuffle(vocab)\n",
    "word2index = {w: i for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        source_word, target_word = self.pairs[idx]\n",
    "        if np.random.randn() < 0.5:\n",
    "            return (word2index[source_word], word2index[target_word]), 1\n",
    "        else:\n",
    "            return (word2index[source_word], np.random.randint(len(vocab))), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(word_pairs[:9_500_000])\n",
    "valid_ds = Dataset(word_pairs[9_500_000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500000, 640726)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8211, 11669), 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2048\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_dl = DataLoader(train_ds, BS, NUM_WORKERS, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, BS, NUM_WORKERS)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=50):\n",
    "        self.embeddings =nn.Embedding(len(vocab), hidden_size)\n",
    "            \n",
    "    def forward(self, idxs):\n",
    "        source_word_idx, target_word_idx = idxs\n",
    "        source_embeddings = self.embeddings(source_word_idx)\n",
    "        target_embeddings = self.embeddings(target_word_idx)\n",
    "        return torch.sum(source_embeddings * target_embeddings, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls.cuda(),\n",
    "    Model().cuda(),\n",
    "    loss_func=BCEWithLogitsLossFlat(),\n",
    "    opt_func=Adam,\n",
    "    metrics=[accuracy_multi]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11' class='' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      9.17% [11/120 12:12<2:01:02]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.653435</td>\n",
       "      <td>0.655603</td>\n",
       "      <td>0.788893</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.465147</td>\n",
       "      <td>0.470913</td>\n",
       "      <td>0.836815</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.388056</td>\n",
       "      <td>0.416087</td>\n",
       "      <td>0.848177</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.352340</td>\n",
       "      <td>0.388206</td>\n",
       "      <td>0.853021</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330585</td>\n",
       "      <td>0.373828</td>\n",
       "      <td>0.853775</td>\n",
       "      <td>01:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.318017</td>\n",
       "      <td>0.362434</td>\n",
       "      <td>0.855701</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.305931</td>\n",
       "      <td>0.353485</td>\n",
       "      <td>0.857078</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.300630</td>\n",
       "      <td>0.348029</td>\n",
       "      <td>0.857473</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.292633</td>\n",
       "      <td>0.343652</td>\n",
       "      <td>0.858848</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.289131</td>\n",
       "      <td>0.337414</td>\n",
       "      <td>0.860736</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.283062</td>\n",
       "      <td>0.334215</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3922' class='' max='4639' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      84.54% [3922/4639 00:50<00:09 0.2798]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_EPOCHS = 120\n",
    "learn.fit(NUM_EPOCHS, lr=1e-3, cbs=SaveModelCallback(fname='text_embeddings', every_epoch=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = learn.model.embeddings.weight.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embeddings(\n",
    "    embeddings,\n",
    "    vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in ['fast', 'lost', 'small', 'true', 'crazy', 'slow']:\n",
    "    print(f'{w}: {e.nn_words_to(e[w])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating embeddings using [word-embeddings-benchmarks](https://github.com/kudkudak/word-embeddings-benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_WS353, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "from web.embedding import Embedding, Vocabulary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MEN\": fetch_MEN(),\n",
    "    \"WS353\": fetch_WS353(),\n",
    "    \"SIMLEX999\": fetch_SimLex999()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_embeddings = Embedding(\n",
    "    Vocabulary(vocab),\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "speech2vec = KeyedVectors.load_word2vec_format('../speech2vec-pretrained-vectors/word2vec/50.vec', binary=False) \n",
    "speech2vec_embeddings = Embedding(Vocabulary(list(speech2vec.vocab.keys())), speech2vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(our_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(speech2vec_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss decrease and improvements on semantic tasks as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "val_losses, accuracies, task_perf = [], [], []\n",
    "for i in range(NUM_EPOCHS):\n",
    "    learn.load(f'text_embeddings_{i}')\n",
    "    loss, accuracy = learn.validate()\n",
    "    val_losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    embeddings = learn.model.embeddings.weight.cpu().detach().numpy()\n",
    "    our_embeddings = Embedding(\n",
    "        Vocabulary([w.lower() for w in vocab]),\n",
    "        embeddings\n",
    "    )\n",
    "\n",
    "    task_perf.append([evaluate_similarity(our_embeddings, data.X, data.y) for name, data in iteritems(tasks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men, ws353, simlex999 = list(zip(*task_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(val_losses, label='val loss')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(men, label='MEN', c='g')\n",
    "ax2.plot(ws353, label='WS353', c='m')\n",
    "ax2.plot(simlex999, label='SIMLEX999', c='y')\n",
    "\n",
    "ax1.legend(loc=[0.07, 0.9])\n",
    "ax2.legend(loc=[0.7, 0.15])\n",
    "\n",
    "ax1.set_xlabel('epochs');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
