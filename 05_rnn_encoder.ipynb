{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.3 s, sys: 3.41 s, total: 28.7 s\n",
      "Wall time: 43.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14276908, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv('data/examples_with_length_speech2vec_vocab.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 15.5 s, total: 33.3 s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn2features = pd.read_pickle('data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(fn, pad_to=70, pad_left=False):\n",
    "    ary = fn2features[fn][:pad_to]\n",
    "    example = np.zeros((pad_to, 13))\n",
    "    if pad_left:\n",
    "        example[-ary.shape[0]:, :] = ary\n",
    "    else: example[:ary.shape[0], :] = ary\n",
    "    return example.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean = -2\n",
    "dataset_std = 10\n",
    "\n",
    "def normalize_data(ary):\n",
    "    return (ary - dataset_mean) / dataset_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.2 s, sys: 7.08 s, total: 57.3 s\n",
      "Wall time: 57.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features = []\n",
    "for fn in df.target_fn.unique():\n",
    "    features.append(normalize_data(prepare_features(fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0002623361, 1.0108287)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(features).mean(), np.stack(features).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2features_norm = {fn: normalize_data(prepare_features(fn)) for fn, features in fn2features.items()}\n",
    "pd.to_pickle(fn2features_norm, 'data/fn2features_norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 10.2 s, total: 26.5 s\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn2features = pd.read_pickle('data/fn2features_norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.distance_from_target == 1]\n",
    "df = df[(~df.target_word.isna() & ~df.source_word.isna())]\n",
    "df = df[df.in_speech2vec_vocab]\n",
    "df = df[((df.source_length < 71) & (df.target_length < 71) & (df.source_length > 19))]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(df.source_word.unique())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.5205581928731"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_list(): return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 1s, sys: 564 ms, total: 6min 2s\n",
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# word2row_idxs = defaultdict(empty_list)\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     word2row_idxs[row.source_word].append(idx)    \n",
    "\n",
    "# pd.to_pickle(word2row_idxs, 'data/word2row_idxs_speech2vec_vocab_min_length_20_max_length_70_only_driect_neighbors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2row_idxs = pd.read_pickle('data/word2row_idxs_speech2vec_vocab_min_length_20_max_length_70_only_driect_neighbors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, n):\n",
    "        self.vocab = vocab * n\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "    def __getitem__(self, idx):\n",
    "        row_idx = np.random.choice(word2row_idxs[self.vocab[idx]])\n",
    "        source_fn = df.source_fn[row_idx]\n",
    "        target_fn = df.target_fn[row_idx]\n",
    "        x = fn2features_norm[source_fn]\n",
    "        y = fn2features_norm[target_fn]\n",
    "        return np.stack((x, y)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2048\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_dl = DataLoader(Dataset(270), BS, NUM_WORKERS, shuffle=True)\n",
    "valid_dl = DataLoader(Dataset(30), BS, NUM_WORKERS)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got the following error while training:\n",
    "\n",
    "# DataLoader worker (pid 2073) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n",
    "# trying the solution I found here: https://github.com/pytorch/pytorch/issues/5040\n",
    "# which is to execute\n",
    "!sudo umount /dev/shm/ && sudo mount -t tmpfs -o rw,nosuid,nodev,noexec,relatime,size=50G shm /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bidirectional encoder, 1 layer, concatenate hidden state\n",
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=25, num_layers_encoder=1):\n",
    "        self.return_embeddings = False\n",
    "        self.num_layers_encoder = num_layers_encoder\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.encoder= nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=self.num_layers_encoder,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=2*hidden_size+13,\n",
    "            hidden_size=2*hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.lin = nn.Linear(2*hidden_size, 13)\n",
    "            \n",
    "    def forward(self, source_and_target_features):\n",
    "        source_features = source_and_target_features[:, 0]\n",
    "        target_features = source_and_target_features[:, 1]\n",
    "        _, (embeddings, _) = self.encoder(source_features)\n",
    "        \n",
    "        embeddings = embeddings.view(self.num_layers_encoder, 2, source_features.shape[0], self.hidden_size)\n",
    "        embeddings = torch.cat([embeddings[:, 0, :, :], embeddings[:, 1, :, :]], -1)\n",
    "        if self.return_embeddings: return embeddings\n",
    "        \n",
    "        target_features = torch.cat((torch.zeros(target_features.shape[0], 1, 13).cuda(), target_features), 1)\n",
    "        inputs = torch.cat(\n",
    "            (\n",
    "                target_features[:, :-1, :],\n",
    "                embeddings.permute(1, 0, 2).repeat(1, target_features.shape[1]-1, 1)\n",
    "            ), 2)\n",
    "        x, _ = self.decoder(inputs, (embeddings, torch.zeros_like(embeddings)))\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls.cuda(), Model().cuda(), loss_func=MSELoss(), lr=1e-3, opt_func=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-67448de6cb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSaveModelCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rnn_encoder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevery_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlog_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cbs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;34m;\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m;\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "learn.fit(10, cbs=SaveModelCallback(fname='rnn_encoder', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.054690</td>\n",
       "      <td>0.054186</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044579</td>\n",
       "      <td>0.044543</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.040433</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.039516</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035495</td>\n",
       "      <td>0.036346</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034273</td>\n",
       "      <td>0.033954</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.046973</td>\n",
       "      <td>0.046428</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.036980</td>\n",
       "      <td>0.036780</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.034245</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, cbs=SaveModelCallback(fname='1e-3_Adam_tf', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fa3f97ccf10>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('1e-3_Adam_tf_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.033178</td>\n",
       "      <td>0.032864</td>\n",
       "      <td>04:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.032137</td>\n",
       "      <td>0.031976</td>\n",
       "      <td>04:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>0.030553</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030182</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031202</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029229</td>\n",
       "      <td>0.028962</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.028558</td>\n",
       "      <td>0.030982</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.028113</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.028064</td>\n",
       "      <td>0.027391</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>0.027337</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.028782</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.027768</td>\n",
       "      <td>0.028584</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.031645</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.028607</td>\n",
       "      <td>0.028184</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.027699</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.027013</td>\n",
       "      <td>0.027236</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20, cbs=SaveModelCallback(fname='1e-3_Adam_tf_v2', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>04:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028757</td>\n",
       "      <td>0.028799</td>\n",
       "      <td>04:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>04:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026915</td>\n",
       "      <td>0.026635</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132799</td>\n",
       "      <td>0.118929</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037304</td>\n",
       "      <td>0.037151</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032856</td>\n",
       "      <td>0.033218</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.030447</td>\n",
       "      <td>0.030448</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>0.029276</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.028510</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.028129</td>\n",
       "      <td>0.028010</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>0.027116</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>0.026727</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>0.026414</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>0.026242</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.027896</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.026322</td>\n",
       "      <td>0.028513</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>0.026016</td>\n",
       "      <td>04:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.027412</td>\n",
       "      <td>0.028233</td>\n",
       "      <td>04:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20, cbs=SaveModelCallback(fname='1e-3_Adam_tf_v3', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>0.025960</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025180</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>0.025795</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024874</td>\n",
       "      <td>0.024512</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048781</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026201</td>\n",
       "      <td>0.025966</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024596</td>\n",
       "      <td>0.024466</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023883</td>\n",
       "      <td>0.024188</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023850</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.023764</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>0.024358</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.040491</td>\n",
       "      <td>0.065988</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.026709</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.025524</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.025685</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20, cbs=SaveModelCallback(fname='1e-3_Adam_tf_v4', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.024760</td>\n",
       "      <td>0.024634</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.024153</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024077</td>\n",
       "      <td>0.023993</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023705</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.023713</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023631</td>\n",
       "      <td>0.023632</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.023595</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023607</td>\n",
       "      <td>0.023491</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>0.023388</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.023518</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.023132</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.023487</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.023265</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.023198</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20, cbs=SaveModelCallback(fname='1e-3_Adam_tf_v5', every_epoch=True), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.023145</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>04:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.023033</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>04:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(2, cbs=SaveModelCallback(fname='1e-3_Adam_tf_v6', every_epoch=True), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.035670</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>04:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030588</td>\n",
       "      <td>0.030552</td>\n",
       "      <td>04:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028262</td>\n",
       "      <td>0.028195</td>\n",
       "      <td>04:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>0.026683</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.026035</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025712</td>\n",
       "      <td>0.025561</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.024697</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024467</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023898</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.024065</td>\n",
       "      <td>0.023998</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.023835</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.023522</td>\n",
       "      <td>0.023399</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.023436</td>\n",
       "      <td>0.023153</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.023062</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.026801</td>\n",
       "      <td>0.025067</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.023204</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.029148</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.023862</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.025097</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.023133</td>\n",
       "      <td>0.022987</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.023264</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.025592</td>\n",
       "      <td>0.025494</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.023751</td>\n",
       "      <td>0.023767</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.023531</td>\n",
       "      <td>0.023682</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.022907</td>\n",
       "      <td>0.022833</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.022726</td>\n",
       "      <td>0.022772</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.022723</td>\n",
       "      <td>0.023165</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.024529</td>\n",
       "      <td>0.024083</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.022425</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.025033</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.023089</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.024767</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.022380</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.022374</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.022246</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>0.022984</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>0.023174</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.023905</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.022352</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.022177</td>\n",
       "      <td>0.022198</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.022238</td>\n",
       "      <td>0.022052</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.021851</td>\n",
       "      <td>04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.052109</td>\n",
       "      <td>0.043253</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.023293</td>\n",
       "      <td>0.023153</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.028183</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.023112</td>\n",
       "      <td>0.026058</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.024908</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.022701</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(60, cbs=SaveModelCallback(fname='1e-3_Adam_tf_v7', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='58' class='' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      96.67% [58/60 4:31:04<09:20]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021380</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021312</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.021166</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.021083</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>0.021101</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.021041</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021036</td>\n",
       "      <td>0.020984</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.021086</td>\n",
       "      <td>0.021030</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.021007</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.020890</td>\n",
       "      <td>0.020974</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.020923</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020898</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.020891</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.020759</td>\n",
       "      <td>0.020898</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.020932</td>\n",
       "      <td>0.020865</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.020735</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>04:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.020673</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.020786</td>\n",
       "      <td>04:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>04:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.020792</td>\n",
       "      <td>0.020841</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.020857</td>\n",
       "      <td>0.020788</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.020754</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.020932</td>\n",
       "      <td>0.020777</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0.020782</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.020754</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.020853</td>\n",
       "      <td>0.020720</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020718</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.020899</td>\n",
       "      <td>0.020682</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.020685</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.020813</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.020708</td>\n",
       "      <td>0.020735</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.020881</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.020721</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.020763</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.020663</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>0.020629</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0.020672</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.020758</td>\n",
       "      <td>0.020665</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.020402</td>\n",
       "      <td>0.020616</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.020708</td>\n",
       "      <td>0.020680</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.020630</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.020625</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.020621</td>\n",
       "      <td>0.020730</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4440' class='' max='4467' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      99.40% [4440/4467 04:05<00:01 0.0207]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(60, cbs=SaveModelCallback(fname='1e-4_Adam_tf_v7', every_epoch=True), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f0b36f774d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('1e-4_Adam_tf_v7_57')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate embedding for each unique word in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_utterances = df[df.set_name.isin(['train-clean-360', 'train-clean-100', 'dev-clean'])].drop_duplicates(['source_fn'])\n",
    "df_unique_utterances.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetAllUtterances():\n",
    "    def __len__(self):\n",
    "        return df_unique_utterances.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        source_fn = df_unique_utterances.iloc[idx].source_fn\n",
    "        target_fn = df_unique_utterances.iloc[idx].target_fn\n",
    "        x = normalize_data(prepare_features(source_fn, pad_left=True))\n",
    "        y = normalize_data(prepare_features(target_fn))\n",
    "        return np.stack((x, y)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl = DataLoader(DatasetAllUtterances(), BS, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.15 s, sys: 6.12 s, total: 15.3 s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn.model.return_embeddings = True\n",
    "learn.model.train = False\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for batch in all_dl:\n",
    "        embeddings = learn.model(batch[0].cuda())\n",
    "        all_embeddings.append(embeddings.detach().cpu().squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1810253, 50])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.return_embeddings = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(all_dl):\n",
    "        outputs = learn.model(batch[0].cuda())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b376b7a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[31].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][31].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b37dc77d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[0].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][0].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b388e2d10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[30].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][30].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b3906fb50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[15].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][15].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 316 ms, total: 2min 34s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2row_idxs_unique_utterances = defaultdict(empty_list)\n",
    "\n",
    "for idx, row in df_unique_utterances.iterrows():\n",
    "    word2row_idxs_unique_utterances[row.source_word].append(idx)\n",
    "    \n",
    "pd.to_pickle(word2row_idxs_unique_utterances, 'word2row_idxs_unique_utterances_max_length_speech2vec_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2row_idxs_unique_utterances = pd.read_pickle('word2row_idxs_unique_utterances_max_length_speech2vec_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2embedding = {}\n",
    "\n",
    "for k, v in word2row_idxs_unique_utterances.items():\n",
    "    word2embedding[k] = all_embeddings[np.array(v)].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered rows with nan values: 0\n"
     ]
    }
   ],
   "source": [
    "word2embedding_without_nans= {}\n",
    "nans_encountered = 0\n",
    "for k, v in word2embedding.items():\n",
    "    if k in vocab and k == k and (not np.isnan(v.numpy()).any()):\n",
    "        word2embedding_without_nans[k] = v.numpy()\n",
    "    else: nans_encountered += 1\n",
    "\n",
    "print(f'Encountered rows with nan values: {nans_encountered}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embeddings(\n",
    "    np.array(list(word2embedding_without_nans.values())),\n",
    "    [w.lower() for w in list(word2embedding_without_nans.keys())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast: ['fast', 'priest', 'trust', 'legs', 'cast']\n",
      "lost: ['lost', 'paused', 'closed', 'most', 'beast']\n",
      "small: ['small', 'call', 'tall', 'cell', 'bow']\n",
      "true: ['true', 'two', 'through', 'too', 'to']\n",
      "crazy: ['crazy', 'freely', 'liberty', 'hearty', 'party']\n",
      "slow: ['slow', 'so', 'swallow', 'below', 'subtle']\n"
     ]
    }
   ],
   "source": [
    "for w in ['fast', 'lost', 'small', 'true', 'crazy', 'slow']:\n",
    "    print(f'{w}: {e.nn_words_to(e[w])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating embeddings using [word-embeddings-benchmarks](https://github.com/kudkudak/word-embeddings-benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_WS353, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "from web.embedding import Embedding, Vocabulary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MEN\": fetch_MEN(),\n",
    "    \"WS353\": fetch_WS353(),\n",
    "    \"SIMLEX999\": fetch_SimLex999()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_embeddings = Embedding(\n",
    "    Vocabulary([w.lower() for w in list(word2embedding_without_nans.keys())]),\n",
    "    np.array(list(word2embedding_without_nans.values()))\n",
    ")\n",
    "\n",
    "speech2vec = KeyedVectors.load_word2vec_format('../speech2vec-pretrained-vectors/speech2vec/50.vec', binary=False) \n",
    "speech2vec_embeddings = Embedding(Vocabulary(list(speech2vec.vocab.keys())), speech2vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 417 words. Will replace them with mean vector\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:336: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A = np.vstack(w.get(word, mean_vector) for word in X[:, 0])\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  B = np.vstack(w.get(word, mean_vector) for word in X[:, 1])\n",
      "Missing 66 words. Will replace them with mean vector\n",
      "Missing 26 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN -0.016457845881016953\n",
      "Spearman correlation of scores on WS353 0.0895924100304081\n",
      "Spearman correlation of scores on SIMLEX999 -0.08322106510718805\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(our_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 392 words. Will replace them with mean vector\n",
      "Missing 61 words. Will replace them with mean vector\n",
      "Missing 24 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.5896756323911225\n",
      "Spearman correlation of scores on WS353 0.49890235673392536\n",
      "Spearman correlation of scores on SIMLEX999 0.28202624769092116\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(speech2vec_embeddings, data.X, data.y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
