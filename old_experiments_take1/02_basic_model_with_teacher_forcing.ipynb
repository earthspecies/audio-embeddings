{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.1 s, sys: 3.5 s, total: 32.6 s\n",
      "Wall time: 32.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17937758, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv('data/examples.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "      <th>source_fn</th>\n",
       "      <th>target_fn</th>\n",
       "      <th>set_name</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>distance_from_target</th>\n",
       "      <th>audio_fpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>FELT</td>\n",
       "      <td>8af4aebcf4a74004b02db9f88d99e89a</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>THAT</td>\n",
       "      <td>8af4aebcf4a74004b02db9f88d99e89a</td>\n",
       "      <td>2f60546c930c47068ee0a129e6d51c39</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>2</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FELT</td>\n",
       "      <td>I</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>8af4aebcf4a74004b02db9f88d99e89a</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FELT</td>\n",
       "      <td>THAT</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>2f60546c930c47068ee0a129e6d51c39</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>1</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FELT</td>\n",
       "      <td>IT</td>\n",
       "      <td>1cb9442ec1a6468282da309756e2ff57</td>\n",
       "      <td>155ad336d88c4cbf814a1237983b5b18</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>7000</td>\n",
       "      <td>83696</td>\n",
       "      <td>2</td>\n",
       "      <td>data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_word target_word                         source_fn  \\\n",
       "0           I        FELT  8af4aebcf4a74004b02db9f88d99e89a   \n",
       "1           I        THAT  8af4aebcf4a74004b02db9f88d99e89a   \n",
       "2        FELT           I  1cb9442ec1a6468282da309756e2ff57   \n",
       "3        FELT        THAT  1cb9442ec1a6468282da309756e2ff57   \n",
       "4        FELT          IT  1cb9442ec1a6468282da309756e2ff57   \n",
       "\n",
       "                          target_fn         set_name  speaker_id  book_id  \\\n",
       "0  1cb9442ec1a6468282da309756e2ff57  train-clean-360        7000    83696   \n",
       "1  2f60546c930c47068ee0a129e6d51c39  train-clean-360        7000    83696   \n",
       "2  8af4aebcf4a74004b02db9f88d99e89a  train-clean-360        7000    83696   \n",
       "3  2f60546c930c47068ee0a129e6d51c39  train-clean-360        7000    83696   \n",
       "4  155ad336d88c4cbf814a1237983b5b18  train-clean-360        7000    83696   \n",
       "\n",
       "   distance_from_target  \\\n",
       "0                     1   \n",
       "1                     2   \n",
       "2                     1   \n",
       "3                     1   \n",
       "4                     2   \n",
       "\n",
       "                                                        audio_fpath  \n",
       "0  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "1  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "2  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "3  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  \n",
       "4  data/LibriSpeech/train-clean-360/7000/83696/7000-83696-0000.flac  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = df[df.set_name.isin(['train-clean-360', 'train-clean-100', 'dev-clean'])]\n",
    "valid_examples = df[df.set_name == 'test-clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159688530, 1751292)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples.size, valid_examples.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_of_example = 291\n",
    "mean_length_of_exapmple = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8eb68ba710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pd.read_pickle('data/examples/1cb9442ec1a6468282da309756e2ff57.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(row, col, pad_to=max_length_of_example, pad_left=False):\n",
    "    ary = pd.read_pickle(f'data/examples/{row[col]}.pkl')\n",
    "    example = np.zeros((pad_to, 13))\n",
    "    if pad_left:\n",
    "        example[-ary.shape[0]:, :] = ary\n",
    "    else: example[:ary.shape[0], :] = ary\n",
    "    return example.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = Datasets(\n",
    "    df,\n",
    "    [lambda row: prepare_features(row, 'source_fn', pad_left=True),\n",
    "     lambda row: prepare_features(row, 'target_fn'),\n",
    "     lambda row: prepare_features(row, 'target_fn')],\n",
    "    n_inp=2,\n",
    "    splits = [train_examples.index, valid_examples.index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 32\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_dl = DataLoader(dss.train, BS, NUM_WORKERS, shuffle=False)\n",
    "valid_dl = DataLoader(dss.valid, BS, NUM_WORKERS)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umount: /dev/shm/: target is busy\r\n",
      "        (In some cases useful info about processes that\r\n",
      "         use the device is found by lsof(8) or fuser(1).)\r\n"
     ]
    }
   ],
   "source": [
    "# Got the following error while training:\n",
    "\n",
    "# DataLoader worker (pid 2073) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n",
    "# trying the solution I found here: https://github.com/pytorch/pytorch/issues/5040\n",
    "# which is to execute\n",
    "!sudo umount /dev/shm/ && sudo mount -t tmpfs -o rw,nosuid,nodev,noexec,relatime,size=50G shm /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=50):\n",
    "        self.encoder= nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.lin = nn.Linear(hidden_size, 13)\n",
    "            \n",
    "    def forward(self, source_features, target_features):\n",
    "        _, (embeddings, cell) = self.encoder(source_features)\n",
    "        input = torch.cat(\n",
    "            (\n",
    "                target_features[:, :-1, :],\n",
    "                embeddings.permute(1, 0, 2).repeat(1, target_features.shape[1]-1, 1)\n",
    "            ), 2)\n",
    "        x, _ = self.decoder(target_features[:, :-1, :], (embeddings, cell))\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = MSELoss()\n",
    "def targ_trunc_MSE(preds, targs):\n",
    "    return mse_loss(preds, targs[:, 1:, :])\n",
    "\n",
    "learn = Learner(dls.cuda(), Model().cuda(), loss_func=targ_trunc_MSE, lr=1e-3, opt_func=SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, cbs=SaveModelCallback(fname='1e-3_SGD', every_epoch=True), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate embedding for each unique word in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_utterances = df[df.set_name.isin(['train-clean-360', 'train-clean-100', 'dev-clean'])].drop_duplicates(['source_fn'])\n",
    "df_unique_utterances.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = Datasets(\n",
    "    df_unique_utterances,\n",
    "    [lambda row: prepare_features(row, 'source_fn', pad_left=True),\n",
    "     lambda row: prepare_features(row, 'target_fn'),\n",
    "     lambda row: prepare_features(row, 'target_fn')],\n",
    "    n_inp=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_utterances_dl = DataLoader(dss, BS, NUM_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 44s, sys: 1min 56s, total: 24min 40s\n",
      "Wall time: 33min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_embeddings = []\n",
    "with torch.no_grad():\n",
    "    learn.model.train = False\n",
    "    for batch in all_utterances_dl:\n",
    "        _, (embeddings, _) = learn.model.encoder(batch[0].cuda())\n",
    "        all_embeddings.append(embeddings.view(embeddings.shape[1], -1).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4638516, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in all_utterances_dl:\n",
    "        outputs = learn.model(batch[0].cuda(), batch[1].cuda())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d5d39a7d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[-1].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][-1].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d5cacdf50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[-10].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][-10].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d5ca148d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(outputs[31].cpu().numpy().T[:, :20])\n",
    "axs[1].imshow(batch[1][31].cpu().numpy().T[:, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 41s, sys: 1.12 s, total: 6min 42s\n",
      "Wall time: 6min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def empty_list(): return list()\n",
    "word2row_idxs_unique_utterances = defaultdict(empty_list)\n",
    "\n",
    "for idx, row in df_unique_utterances.iterrows():\n",
    "    word2row_idxs_unique_utterances[row.source_word].append(idx)\n",
    "    \n",
    "pd.to_pickle(word2row_idxs_unique_utterances, 'word2row_idxs_unique_utterances.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2row_idxs_unique_utterances = pd.read_pickle('word2row_idxs_unique_utterances.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2embedding = {}\n",
    "\n",
    "for k, v in word2row_idxs_unique_utterances.items():\n",
    "    word2embedding[k] = all_embeddings[np.array(v)].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered rows with nan values: 1\n"
     ]
    }
   ],
   "source": [
    "word2embedding_without_nans= {}\n",
    "nans_encountered = 0\n",
    "for k, v in word2embedding.items():\n",
    "    if k == k and (not np.isnan(v.numpy()).any()):\n",
    "        word2embedding_without_nans[k] = v.numpy()\n",
    "    else: nans_encountered += 1\n",
    "\n",
    "print(f'Encountered rows with nan values: {nans_encountered}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings():\n",
    "    def __init__(self, embeddings, index2word):\n",
    "        '''embeddings - numpy array of embeddings, index2word - list of words corresponding to embeddings'''\n",
    "        assert len(embeddings) == len(index2word)\n",
    "        self.vectors = embeddings\n",
    "        self.i2w = index2word\n",
    "        self.w2i = {w:i for i, w in enumerate(index2word)}\n",
    "            \n",
    "    def analogy(self, a, b, c, n=5, discard_question_words=True):\n",
    "        '''\n",
    "        a is to b as c is to ?\n",
    "        \n",
    "        Performs the following algebraic calculation: result = emb_a - emb_b + emb_c\n",
    "        Looks up n closest words to result.\n",
    "        \n",
    "        Implements the embedding space math behind the famous word2vec example:\n",
    "        king - man + woman = queen\n",
    "        '''\n",
    "        question_word_indices = [self.w2i[word] for word in [a, b, c]]\n",
    "        a, b, c = [self.vectors[idx] for idx in question_word_indices] \n",
    "        result = a - b + c\n",
    "        \n",
    "        if discard_question_words: return self.nn_words_to(result, question_word_indices, n)\n",
    "        else:                      return self.nn_words_to(result, n=n)\n",
    "        \n",
    "    def nn_words_to(self, vector, skip_indices=[], n=5):\n",
    "        nn_indices = self.word_idxs_ranked_by_cosine_similarity_to(vector)\n",
    "        nn_words = []\n",
    "        for idx in nn_indices:\n",
    "            if idx in skip_indices: continue\n",
    "            nn_words.append(self.i2w[idx])\n",
    "            if len(nn_words) == n: break\n",
    "        \n",
    "        return nn_words\n",
    "    \n",
    "    def word_idxs_ranked_by_cosine_similarity_to(self, vector):\n",
    "        return np.flip(\n",
    "            np.argsort(self.vectors @ vector / (self.vectors_lengths() * np.linalg.norm(vector, axis=-1)))\n",
    "        )\n",
    "    \n",
    "    def vectors_lengths(self):\n",
    "        if not hasattr(self, 'vectors_length_cache'):\n",
    "            self.vectors_length_cache = np.linalg.norm(self.vectors, axis=-1)\n",
    "        return self.vectors_length_cache\n",
    "    \n",
    "    def __getitem__(self, word):\n",
    "        return self.vectors[self.w2i[word]]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_txt_file(cls, path_to_txt_file, limit=None):\n",
    "        '''create embeddings from word2vec embeddings text file'''\n",
    "        index, vectors = [], []\n",
    "        with open(path_to_txt_file) as f:\n",
    "            f.readline() # discarding the header line\n",
    "            for line in f:\n",
    "                try:\n",
    "                    embedding = np.array([float(s) for s in line.split()[1:]])\n",
    "                    if embedding.shape[0] != 300: continue\n",
    "                    vectors.append(embedding)\n",
    "                    index.append(line.split()[0])\n",
    "                except ValueError: pass # we may have encountered a 2 word embedding, for instance 'New York' or 'w dolinie'\n",
    "                if limit is not None and len(vectors) == limit: break\n",
    "        return cls(np.stack(vectors), index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embeddings(\n",
    "    np.array(list(word2embedding_without_nans.values())),\n",
    "    [w.lower() for w in list(word2embedding_without_nans.keys())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fast', 'stood', 'right', 'will', 'voice']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.nn_words_to(e['fast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lost', 'even', 'now', 'has', 'little']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.nn_words_to(e['lost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['true', 'thing', 'king', 'master', 'most']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.nn_words_to(e['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virtue', 'lived', 'book', 'tell', 'says']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.nn_words_to(e['virtue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['germany', 'forever', 'fruit', 'abandoned', 'surprised']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.nn_words_to(e['germany'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating embeddings using [word-embeddings-benchmarks](https://github.com/kudkudak/word-embeddings-benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_WS353, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "from web.embedding import Embedding, Vocabulary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MEN\": fetch_MEN(),\n",
    "    \"WS353\": fetch_WS353(),\n",
    "    \"SIMLEX999\": fetch_SimLex999()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_embeddings = Embedding(\n",
    "    Vocabulary([w.lower() for w in list(word2embedding_without_nans.keys())]),\n",
    "    np.array(list(word2embedding_without_nans.values()))\n",
    ")\n",
    "\n",
    "speech2vec = KeyedVectors.load_word2vec_format('../speech2vec-pretrained-vectors/speech2vec/50.vec', binary=False) \n",
    "speech2vec_embeddings = Embedding(Vocabulary(list(speech2vec.vocab.keys())), speech2vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 392 words. Will replace them with mean vector\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:336: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  A = np.vstack(w.get(word, mean_vector) for word in X[:, 0])\n",
      "/opt/conda/lib/python3.7/site-packages/web-0.0.1-py3.7.egg/web/evaluate.py:337: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  B = np.vstack(w.get(word, mean_vector) for word in X[:, 1])\n",
      "Missing 61 words. Will replace them with mean vector\n",
      "Missing 24 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.5896756323911225\n",
      "Spearman correlation of scores on WS353 0.49890235673392536\n",
      "Spearman correlation of scores on SIMLEX999 0.28202624769092116\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(speech2vec_embeddings, data.X, data.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing 242 words. Will replace them with mean vector\n",
      "Missing 49 words. Will replace them with mean vector\n",
      "Missing 11 words. Will replace them with mean vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of scores on MEN 0.05776255118596078\n",
      "Spearman correlation of scores on WS353 -0.024383747889449636\n",
      "Spearman correlation of scores on SIMLEX999 -0.1689680172446115\n"
     ]
    }
   ],
   "source": [
    "for name, data in iteritems(tasks):\n",
    "    print(\"Spearman correlation of scores on {} {}\".format(name, evaluate_similarity(our_embeddings, data.X, data.y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
