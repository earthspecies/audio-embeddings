{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of leraning semantic audio embeddings feel daunting - maybe we can help our model by pretraining the encoder to learn to distinguish words from audio?\n",
    "\n",
    "This is providing a crutch to our model - it no longer will be unsupervised in the sense that we will levarge word labels for the pretraining. It might nonetheless be very useful to do as we work towards a fully working end to end unsupervised model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.8 s, sys: 3.69 s, total: 35.5 s\n",
      "Wall time: 54.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17937758, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv('data/examples_with_length_speech2vec_vocab.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[((df.source_length < 70) & (df.target_length < 70) & (df.source_length > 25) & (df.target_length > 25))]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 11.1 s, total: 28.6 s\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn2features = pd.read_pickle('data/fn2feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean = -3\n",
    "dataset_std = 12\n",
    "\n",
    "def normalize_data(ary):\n",
    "    return (ary - dataset_mean) / dataset_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_list(): return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# word2row_idxs = defaultdict(empty_list)\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     word2row_idxs[row.source_word].append(idx)\n",
    "    \n",
    "# pd.to_pickle(word2row_idxs, 'data/word2row_idxs_vocab_subset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2row_idxs = pd.read_pickle('data/word2row_idxs_vocab_subset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(fn, pad_to=69, pad_left=False):\n",
    "    ary = fn2features[fn][:pad_to]\n",
    "    example = np.zeros((pad_to, 13))\n",
    "    if pad_left:\n",
    "        example[-ary.shape[0]:, :] = ary\n",
    "    else: example[:ary.shape[0], :] = ary\n",
    "    return example.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = df.target_word.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        target_fn = self.df.target_fn[idx]\n",
    "        x = normalize_data(prepare_features(target_fn))\n",
    "        return x, vocab.index(self.df.target_word[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = df[df.set_name.isin(['train-clean-360', 'train-clean-100', 'dev-clean'])]\n",
    "valid_examples = df[df.set_name == 'test-clean']\n",
    "\n",
    "train_examples.reset_index(inplace=True, drop=True)\n",
    "valid_examples.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_examples)\n",
    "valid_ds = Dataset(valid_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300062, 36832)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2048\n",
    "LR = 1e-3\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "train_dl = DataLoader(train_ds, BS, NUM_WORKERS, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, BS, NUM_WORKERS)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bidirectional encoder, 1 layer, concatenate hidden state\n",
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=25, num_layers_encoder=3):\n",
    "        self.return_embeddings = False\n",
    "        self.num_layers_encoder = num_layers_encoder\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.encoder= nn.LSTM(\n",
    "            input_size=13,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=self.num_layers_encoder,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=True\n",
    "        ) \n",
    "        \n",
    "        self.lin = nn.Linear(2*hidden_size, len(vocab))\n",
    "            \n",
    "    def forward(self, source_features):\n",
    "        _, (embeddings, _) = self.encoder(source_features)\n",
    "        \n",
    "        embeddings = torch.cat((embeddings[-1], embeddings[-2]), 1)\n",
    "        if self.return_embeddings: return embeddings\n",
    "        \n",
    "        return self.lin(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls.cuda(), Model().cuda(), loss_func=CrossEntropyLossFlat(), lr=1e-3, opt_func=Adam, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.249473</td>\n",
       "      <td>6.229773</td>\n",
       "      <td>0.133308</td>\n",
       "      <td>02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.242486</td>\n",
       "      <td>4.317686</td>\n",
       "      <td>0.318962</td>\n",
       "      <td>02:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.207394</td>\n",
       "      <td>3.340269</td>\n",
       "      <td>0.447899</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.581912</td>\n",
       "      <td>2.761657</td>\n",
       "      <td>0.527395</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.199839</td>\n",
       "      <td>2.421428</td>\n",
       "      <td>0.576998</td>\n",
       "      <td>02:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.925077</td>\n",
       "      <td>2.185860</td>\n",
       "      <td>0.615525</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.739560</td>\n",
       "      <td>2.020813</td>\n",
       "      <td>0.638548</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.581429</td>\n",
       "      <td>1.886971</td>\n",
       "      <td>0.660241</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.467972</td>\n",
       "      <td>1.790694</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>02:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.378024</td>\n",
       "      <td>1.716751</td>\n",
       "      <td>0.683753</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.303027</td>\n",
       "      <td>1.651439</td>\n",
       "      <td>0.692414</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.231586</td>\n",
       "      <td>1.601363</td>\n",
       "      <td>0.701455</td>\n",
       "      <td>02:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.178764</td>\n",
       "      <td>1.550824</td>\n",
       "      <td>0.709926</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.135144</td>\n",
       "      <td>1.508363</td>\n",
       "      <td>0.713401</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.088021</td>\n",
       "      <td>1.485226</td>\n",
       "      <td>0.720786</td>\n",
       "      <td>02:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.050825</td>\n",
       "      <td>1.453714</td>\n",
       "      <td>0.725320</td>\n",
       "      <td>02:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.014823</td>\n",
       "      <td>1.419341</td>\n",
       "      <td>0.733058</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.991190</td>\n",
       "      <td>1.386716</td>\n",
       "      <td>0.736751</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>1.371543</td>\n",
       "      <td>0.738678</td>\n",
       "      <td>02:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.932581</td>\n",
       "      <td>1.349263</td>\n",
       "      <td>0.741421</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.907697</td>\n",
       "      <td>1.333570</td>\n",
       "      <td>0.746769</td>\n",
       "      <td>02:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.887558</td>\n",
       "      <td>1.323636</td>\n",
       "      <td>0.747882</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.871254</td>\n",
       "      <td>1.310166</td>\n",
       "      <td>0.748805</td>\n",
       "      <td>02:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.855871</td>\n",
       "      <td>1.301836</td>\n",
       "      <td>0.749321</td>\n",
       "      <td>02:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.839567</td>\n",
       "      <td>1.272230</td>\n",
       "      <td>0.755512</td>\n",
       "      <td>02:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>1.267389</td>\n",
       "      <td>0.757575</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.811707</td>\n",
       "      <td>1.259501</td>\n",
       "      <td>0.759177</td>\n",
       "      <td>02:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.803783</td>\n",
       "      <td>1.255118</td>\n",
       "      <td>0.762543</td>\n",
       "      <td>02:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.788887</td>\n",
       "      <td>1.248293</td>\n",
       "      <td>0.761376</td>\n",
       "      <td>02:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.781536</td>\n",
       "      <td>1.236010</td>\n",
       "      <td>0.764145</td>\n",
       "      <td>02:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(30, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/encoder_weights_supervised.pth')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('encoder_weights_supervised')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
